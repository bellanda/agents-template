import re
import time

from bs4 import BeautifulSoup

from utilities.web_search import optimized_requests


def perform_scraping(url: str) -> str:
    start_time = time.perf_counter()

    response = optimized_requests.get(url)

    # Verifica se a resposta √© um erro (string) ou sucesso (Response)
    if optimized_requests.is_error_response(response):
        end_time = time.perf_counter()
        error_msg = optimized_requests.get_error_message(response)
        print(f"‚ùå Failed to scrape {url} in {end_time - start_time:.2f}s: {error_msg}")
        return f"ERRO_SCRAPING: {error_msg}"

    try:
        soup = BeautifulSoup(response.text, "html.parser")
        text = soup.get_text(strip=False)

        end_time = time.perf_counter()
        print(f"üîç Scraped {url} in {end_time - start_time:.2f}s")

        # Strip inteligente
        return smart_strip(text)

    except Exception as e:
        end_time = time.perf_counter()
        print(f"‚ùå Error parsing {url} in {end_time - start_time:.2f}s: {str(e)}")
        return f"ERRO_PARSING: {url} - {str(e)}"


def smart_strip(text: str) -> str:
    """
    Remove espa√ßos e quebras de linha excessivos, mantendo formata√ß√£o leg√≠vel.
    - Reduz m√∫ltiplos espa√ßos para no m√°ximo 2
    - Reduz m√∫ltiplas quebras de linha para no m√°ximo 3
    - Remove espa√ßos no in√≠cio e fim de cada linha
    """
    # Remove espa√ßos no in√≠cio e fim
    text = text.strip()

    # Substitui m√∫ltiplos espa√ßos (6 ou mais) por 2 espa√ßos
    text = re.sub(r" {6,}", "  ", text)

    # Substitui m√∫ltiplos espa√ßos (3-5) por 1 espa√ßo
    text = re.sub(r" {3,5}", " ", text)

    # Remove espa√ßos no in√≠cio e fim de cada linha
    lines = text.split("\n")
    lines = [line.strip() for line in lines]
    text = "\n".join(lines)

    # Substitui m√∫ltiplas quebras de linha (5 ou mais) por 3
    text = re.sub(r"\n{5,}", "\n\n\n", text)

    # Substitui m√∫ltiplas quebras de linha (4) por 2
    text = re.sub(r"\n{4}", "\n\n", text)

    return text


if __name__ == "__main__":
    import pathlib
    import sys

    sys.path.append("/home/bellanda/code/projects-templates/agents-template")

    current_dir = pathlib.Path(__file__).parent

    from llms.groq import call_groq_llm

    result = perform_scraping("https://bellanda.github.io/dev/")
    with open(current_dir / "result.txt", "w", encoding="utf-8") as f:
        f.write(result)

    prompt = f"""
        Voc√™ √© um analista de conte√∫dos da web especializado em condensar grandes volumes de texto.

        ## Objetivo
        Receber **exatamente 5** p√°ginas completas ‚Äî cada uma no formato:

        ### <T√≠tulo da P√°gina N>
        <corpo completo da P√°gina N>

        e devolver **uma resposta √∫nica** que:
        1. ConteÃÇm todas as informacÃßoÃÉes essenciais (fatos, nuÃÅmeros, datas, nomes, conclusoÃÉes).
        2. Elimina repeticÃßoÃÉes e detalhes triviais (ex.: c√≥digo, an√∫ncios, bot√µes).
        3. Resolva poss√≠veis contradi√ß√µes ou indique diverg√™ncias, se houver.
        4. J√° esteja pronta para ser lida por um agente-chamador (n√£o precisa de p√≥s-processamento).

        ## Passos internos (Chain-of-Thought oculto)
        1. **Para cada p√°gina**: extraia
        ‚Ä¢ T√≥picos centrais  
        ‚Ä¢ Dados quantitativos e cita√ß√µes relevantes  
        ‚Ä¢ Conclus√£o ou take-away principal
        2. **Agrupe** t√≥picos semelhantes das cinco p√°ginas e integre informa√ß√µes complementares.
        3. **Detecte incoer√™ncias**: se dois textos divergem, aponte brevemente (‚ÄúFonte A diz X, Fonte B diz Y‚Äù).
        4. **Monte o resumo final** (veja formato abaixo).

        ## Formato de sa√≠da (exporte apenas o texto abaixo)
        **Resumo Integrado (‚â§ 250 palavras)**  
        Um par√°grafo ou lista curta que responda de forma direta ao tema comum das p√°ginas.

        **Principais Pontos Organizados**
        - *T√≥pico 1*: frase-s√≠ntese + dados / exemplos
        - *T√≥pico 2*: ‚Ä¶
        *(Use no m√°x. 7 bullets.)*

        **Notas de Diverg√™ncia (opcional)**
        - Se houver conflito: ‚ÄúP√°gina 1 vs P√°gina 3: ‚Ä¶‚Äù

        **Mapa de Origem**
        T√≠tulo da P√°gina 1 ‚Üí [ideia-chave-1, ideia-chave-2]  
        T√≠tulo da P√°gina 2 ‚Üí ‚Ä¶  
        *(Cite apenas as ideias condensadas ‚Äî n√£o copie texto literal.)*

        ## Regras
        - Escreva em **portugu√™s claro e conciso**.
        - N√£o invente informa√ß√µes; baseie-se apenas no texto recebido.
        - N√£o inclua explica√ß√µes sobre seu racioc√≠nio.
        - N√£o formate como c√≥digo nem rode markdown excessivo (use headings e bullets simples).
        - Se faltar uma das 5 p√°ginas, mencione: ‚ÄúAviso: p√°gina X ausente‚Äù.

        (Conte√∫do fornecido come√ßa abaixo.)
        {result}
    """

    with open(current_dir / "result_summarized.txt", "w", encoding="utf-8") as f:
        f.write(call_groq_llm("llama3-8b-8192", prompt, max_tokens=1024))
