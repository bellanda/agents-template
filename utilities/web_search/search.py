import pathlib
import sys

sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))

from llms.nvidia import call_nvidia_llm
from utilities.web_search.duckduckgo import search as search_duckduckgo
from utilities.web_search.scrapper import perform_scraping

BASE_DIR = pathlib.Path(__file__).parent.parent.parent


def search(query: str) -> str:
    print(f"ğŸ” [SEARCH] Iniciando busca para: '{query}'")
    results = search_duckduckgo(query)
    print(f"ğŸ“Š [SEARCH] Encontrados {len(results)} resultados do DuckDuckGo")

    full_content = ""

    for i, result in enumerate(results):
        content = perform_scraping(result["url"])
        full_content += f"PÃ¡gina {i + 1}\nURL: {result['url']}\nTÃ­tulo: {result['title']}\nDescriÃ§Ã£o: {result['description']}\n\n{content}\n\n"

    prompt = f"""
        VocÃª Ã© um analista de conteÃºdos da web especializado em condensar grandes volumes de texto.

        ## Objetivo
        Receber **exatamente 5** pÃ¡ginas completas â€” cada uma no formato:

        ### <TÃ­tulo da PÃ¡gina N>
        <corpo completo da PÃ¡gina N>

        e devolver **uma resposta Ãºnica em Markdown** que:
        1. ContÃ©m todas as informaÃ§Ãµes essenciais (fatos, nÃºmeros, datas, nomes, conclusÃµes).
        2. Elimina repetiÃ§Ãµes e detalhes triviais (ex.: cÃ³digo-fonte, anÃºncios, botÃµes).
        3. Resolve possÃ­veis contradiÃ§Ãµes ou indica divergÃªncias, se houver.
        4. JÃ¡ esteja pronta para ser exibida no front-end (nÃ£o precisa de pÃ³s-processamento).

        ## Passos internos (Chain-of-Thought oculto)  
        1. **Para cada pÃ¡gina**: extraia  
        â€¢ TÃ³picos centrais  
        â€¢ Dados quantitativos e citaÃ§Ãµes relevantes  
        â€¢ ConclusÃ£o ou insight principal  
        2. **Agrupe** tÃ³picos semelhantes das cinco pÃ¡ginas e integre informaÃ§Ãµes complementares.  
        3. **Detecte incoerÃªncias**: se dois textos divergem, aponte brevemente (â€œFonte A diz X, Fonte B diz Yâ€).  
        4. **Monte o resumo final** (veja formato abaixo).

        ## Formato de saÃ­da (exporte **apenas** o texto abaixo)  
        > Use **Markdown**, cabeÃ§alhos, bullets e **emojis** ğŸ‘€ para tornar a visualizaÃ§Ã£o agradÃ¡vel.  
        > Inclua o **link da URL** de cada pÃ¡gina onde indicado.

        **Resumo Integrado**  
        (Escreva de forma clara e concisa; escolha um tamanho que cubra todos os pontos essenciais sem se alongar demais.)

        **Principais Pontos Organizados**  
        - ğŸ”¹ *TÃ³pico 1*: frase-sÃ­ntese + dados / exemplos  
        - ğŸ”¹ *TÃ³pico 2*: â€¦  
        *(MÃ¡x. 7 bullets.)*

        **Notas de DivergÃªncia âš ï¸ (opcional)**  
        - Se houver conflito: â€œPÃ¡gina 1 vs PÃ¡gina 3: â€¦â€

        **Mapa de Origem**  
        [ğŸ”— PÃ¡gina 1 â€“ TÃ­tulo](URL-1) â†’ ideia-chave-1, ideia-chave-2  
        [ğŸ”— PÃ¡gina 2 â€“ TÃ­tulo](URL-2) â†’ â€¦  
        *(Liste apenas as ideias condensadas â€” nÃ£o copie texto literal.)*

        ## Regras
        - Escreva em **portuguÃªs** claro.
        - NÃ£o invente informaÃ§Ãµes; baseie-se somente no texto das pÃ¡ginas.
        - Se faltar uma das 5 pÃ¡ginas, mencione: â€œAviso: pÃ¡gina X ausenteâ€.  
        - Evite blocos de cÃ³digo; use formataÃ§Ã£o simples de Markdown.
        
        CONTEÃšDO:
        ```text
        {full_content}
        ```
    """
    # Create scrapper directory
    SCRAPPER_DIR = BASE_DIR / "data/scrapper"
    SCRAPPER_DIR.mkdir(parents=True, exist_ok=True)

    # Save raw web search results
    RAW_WEB_SEARCH_RESULTS_FILE = SCRAPPER_DIR / "raw_web_search_results.txt"
    with open(RAW_WEB_SEARCH_RESULTS_FILE, "w", encoding="utf-8") as f:
        f.write(full_content)

    # Summarize web search results
    result_summarized = call_nvidia_llm("meta/llama-4-scout-17b-16e-instruct", prompt, max_tokens=1024)

    # Save summarized web search results
    SUMMARIZED_WEB_SEARCH_RESULTS_FILE = SCRAPPER_DIR / "summarized_web_search_results.txt"
    with open(SUMMARIZED_WEB_SEARCH_RESULTS_FILE, "w", encoding="utf-8") as f:
        f.write(result_summarized)

    return result_summarized


if __name__ == "__main__":
    search("Gustavo Bellanda")
